---
# tasks file for oraclerestart

- name: Set authorized key took from file
  authorized_key:
    user: oracle
    state: present
    key: "{{ lookup('file', '/root/.ssh/id_rsa.pub') }}"

- name: ensure private key and public one are present
  copy: 
    src: keys/
    dest: "/home/oracle/.ssh/"
    mode: 0400
    owner: oracle
    group: oinstall
  with_items:
    - id_rsa

- name: Accept ssh keys from all other cluster nodes
  shell: "ssh -oStrictHostKeyChecking=no {{ item }} hostname"
  become: yes
  become_user: oracle
  with_items:
    - "{{ ansible_play_batch }}"
      
- name: 'Extend the u01'
  lvol:
    vg: vg01
    lv: u01
    size: 29G
    shrink: no
    resizefs: yes

- name: Oracle CRS required packages
  yum: 
    name=device-mapper-multipath,ksh,sysstat,smartmontools,gcc-c++,net-tools
    state=latest

- name: Oracle CRS required packages
  yum: 
    name=cvuqdisk
    state=latest
    disable_gpg_check=yes 

- name: udev 55
  copy:
    src: 55-usm.rules
    dest: /etc/udev/rules.d/55-usm.rules

- name: udev 12
  copy:
    src: 12-dm-permissions.rules
    dest: /etc/udev/rules.d/12-dm-permissions.rules

- name: udev 10
  copy:
    src: 10-scsi-asm.rules
    dest: /etc/udev/rules.d/10-scsi-asm.rules

- name: install udevasm.sh
  copy:
    src: udevasm.sh
    dest: /etc/udev/udevasm.sh
    mode: '0750'

- name: reload udev
  command: udevadm trigger

- name: Wait for ASM DISK detection
  wait_for:
    path: /dev/asmshared0103      
    delay: 0
    timeout: 30
    state: present

# - name: multipath.conf
#   copy:
#     src: multipath.conf
#     dest: /etc/multipath.conf
#     mode: '0644'
# - command: mpathconf --enable
# - name: start multipath
#   systemd:
#     name: multipathd
#     state: restarted

- name: list files
  find:
    paths: /dev/
    patterns: "asmshared*p1"
    file_type: link
  register: asm_disks

# - name: ASM paritions detected
#   debug: 
#     msg: "ASM DISKs {{ asm_disks }}"

# - debug:
#     var: item.path
#   with_items: "{{ asm_disks.files }}"

- debug:
    msg: "{{ item.path }}"
  with_items: "{{ asm_disks.files }}"

- name: Build a list of all ASM disk paritions
  set_fact:
    asm_disk_partitions: "{{ asm_disk_partitions }} + [ '{{ item.path }}' ]"
  with_items: "{{ asm_disks.files }}"

- debug:
    var: asm_disk_partitions

- name: ASM paritions
  parted:
    device: "/dev/{{item}}"
    label: gpt
    number: 1
    state: present    
  with_items: ["asmshared0100", "asmshared0101", "asmshared0102", "asmshared0103"]

- name: "ora_1_env file"
  template:
    src: ora_1_env.ASM
    dest: "/home/oracle/.ora_1_env"

- name: "Gi fome"
  file:
    path: "/oracle/u01/gi/{{ oracle_ver_path }}"
    state: directory
    owner: oracle
    group: oinstall
    recurse: yes
    mode: '0755'

- name: "Oracle KB"
  file:
    path: "/home/oracle/.ORACLE_KB"
    state: directory
    owner: oracle
    group: oinstall

- name: check if Oracle CRS unpacked
  stat: 
    path: /oracle/u01/gi/{{ oracle_ver_path }}/bin/
  register: crs_unpacked
  
- debug:
    msg: "Install package exists: {{ crs_unpacked.stat.exists }} on {{ first_rac_node }}"

- include: download.package.yml
  when: crs_unpacked.stat.exists != True

- name: check if Oracle CRS set up
  stat: 
    path: /oracle/u01/oraInventory/oraInst.loc
  register: crs_set_up
  when: ansible_hostname == first_rac_node

- debug:
    msg: "Install oraInventory exists: {{ crs_set_up }} "

- name: fqdn
  include_tasks: fqdn.yml
  loop: "{{ ansible_play_batch }}"

- debug:
    var: crs_nodes_fqdn

- include: setup.grid.yml
  when: ansible_hostname == first_rac_node and crs_set_up.stat.exists != True

- name: root.sh
  shell: /oracle/u01/gi/{{ oracle_ver_path }}/root.sh
  when: oracle_ohasd_service.status.LoadState == "not-found"

- name: orainstRoot.sh
  shell: /oracle/u01/oraInventory/orainstRoot.sh
  args:
    creates: /etc/oraInst.loc
  when: ansible_hostname == first_rac_node

- name: "ASM test"
  block:
    - debug:
        msg: "ASM not ONLINE"
    - name: install grid.rsp
      copy:
        src: grid.rsp
        dest: /oracle/u01/gi/grid.rsp
        mode: '0644'

    - name: Grid Setup ASM (part II)
      shell: "./gridSetup.sh -executeConfigTools -responseFile /oracle/u01/gi/grid.rsp -silent"
      args:
        chdir: "/oracle/u01/gi/{{ oracle_ver_path }}"
      register: grid_setup_out2
    - debug: 
        msg: "ansible_hostname: {{ ansible_hostname }}"
    - debug: 
        msg: "first_rac_node: {{ first_rac_node }}"
    - debug: 
        msg: "gridSetup: {{ grid_setup_out2 }}"
    - debug: 
        msg: "Return code is {{ grid_setup_out2.rc }}"
      when: grid_setup_out2.rc >= 2

  #   - name: delete install .zip package
  #     file:
  #       path: /oracle/u01/gi/grid.rsp
  #       state: absent

  # rescue:
  #   - name: delete install .zip package
  #     file:
  #       path: /oracle/u01/gi/grid.rsp
  #       state: absent

  become: yes
  become_user: oracle
  # when:  ansible_hostname == first_rac_node and oracle_asm_status.stdout is not match(".*ONLINE")
  when:  ansible_hostname == first_rac_node

# Not needed for 19c
# - name: file perm fixup
#   file:
#     path: /oracle/u01/gi/{{ oracle_ver_path }}/cdata/localhost/{{ansible_hostname}}.olr
#     owner: oracle
#     group: oinstall
#     mode: '0600'

- name: file perm fixup
  file:
    path: /oracle/u01/gi/{{ oracle_ver_path }}/bin/oracle
    owner: oracle
    group: oinstall
    mode: '6755'

- name: file perm fixup
  file:
    path: /oracle/u01/gi/{{ oracle_ver_path }}
    owner: root
    group: oinstall
    mode: '0755'
